{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    " \n",
    "# Load environment variables from the .env file\n",
    "load_dotenv('.env')\n",
    " \n",
    "# Access environment variables\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TEJKIRAN\\anaconda3\\envs\\deepeval\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model='gemini-pro',google_api_key = GOOGLE_API_KEY)\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model = 'models/embeddings-001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do you call a fish with no eyes?\n",
      "\n",
      "Fsh!\n"
     ]
    }
   ],
   "source": [
    "from deepeval.models.base_model import DeepEvalBaseLLM\n",
    "\n",
    "class GoogleVertextAI(DeepEvalBaseLLM):\n",
    "    \"\"\"Class to implement Vertex AI for DeepEval\"\"\"\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "    \n",
    "    def load_model(self):\n",
    "        return self.model\n",
    "    \n",
    "    def generate(self,prompt:str) -> str:\n",
    "        chat_model = self.load_model()\n",
    "        return chat_model.invoke(prompt).content\n",
    "    \n",
    "    async def a_generate(self,prompt: str) -> str:\n",
    "        chat_model = self.load_model()\n",
    "        res = await chat_model.ainvoke(prompt)\n",
    "        return res.content\n",
    "    \n",
    "    def get_model_name(self):\n",
    "        return \"Vertex AI Model\"\n",
    "    \n",
    "\n",
    "vertexai_gemini = GoogleVertextAI(model = model)\n",
    "print(vertexai_gemini.generate(\"write me a joke\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\TEJKIRAN\\anaconda3\\envs\\deepeval\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for\n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\TEJKIRAN\\anaconda3\\envs\\deepeval\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for\n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\TEJKIRAN\\anaconda3\\envs\\deepeval\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for\n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\TEJKIRAN\\anaconda3\\envs\\deepeval\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for\n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\TEJKIRAN\\anaconda3\\envs\\deepeval\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for\n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\TEJKIRAN\\anaconda3\\envs\\deepeval\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for\n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\TEJKIRAN\\anaconda3\\envs\\deepeval\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for\n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\TEJKIRAN\\anaconda3\\envs\\deepeval\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for\n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 The score is 1.00 because there are no irrelevant statements in the actual output.\n"
     ]
    }
   ],
   "source": [
    "from deepeval import assert_test\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.metrics import AnswerRelevancyMetric\n",
    "\n",
    "test_case = LLMTestCase(\n",
    "    input=\"Python or R? what is Better?\",\n",
    "    actual_output=\"Python is best\"\n",
    ")\n",
    "\n",
    "relevancy_metric = AnswerRelevancyMetric(threshold=0.9,model=vertexai_gemini)\n",
    "\n",
    "relevancy_metric.measure(test_case)\n",
    "print(relevancy_metric.score,relevancy_metric.reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\TEJKIRAN\\anaconda3\\envs\\deepeval\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for\n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\TEJKIRAN\\anaconda3\\envs\\deepeval\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for\n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\TEJKIRAN\\anaconda3\\envs\\deepeval\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for\n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\TEJKIRAN\\anaconda3\\envs\\deepeval\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for\n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 The length of Actual Output is not less than the length of Expected Output.\n"
     ]
    }
   ],
   "source": [
    "from deepeval.test_case import LLMTestCase, LLMTestCaseParams\n",
    "from deepeval.metrics import GEval\n",
    "\n",
    "test_case = LLMTestCase(\n",
    "    input=\"Python or R? what is Better?\",\n",
    "    actual_output=\"Python is better\",\n",
    "    expected_output=\"Python\"\n",
    ")\n",
    "\n",
    "correctness_metric = GEval(\n",
    "    name='ABC',\n",
    "    criteria = \"ABC - determine if output is short or not\",\n",
    "    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT, LLMTestCaseParams.EXPECTED_OUTPUT], model = vertexai_gemini\n",
    ")\n",
    "\n",
    "correctness_metric.measure(test_case)\n",
    "print(correctness_metric.score,correctness_metric.reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating our own metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from deepeval.scorer import Scorer\n",
    "from deepeval.metrics import BaseMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "\n",
    "class RougeMetric(BaseMetric):\n",
    "    def __init__(self,threshold:float = 0.5):\n",
    "        self.threshold = threshold\n",
    "        self.scorer = Scorer()\n",
    "\n",
    "    def measure(self, test_case: LLMTestCase):\n",
    "        self.score = self.scorer.rouge_score(\n",
    "            prediction=test_case.actual_output,\n",
    "            target=test_case.expected_output,\n",
    "            score_type=\"rouge1\"\n",
    "        )\n",
    "        self.success = self.score >= self.threshold\n",
    "        return self.score\n",
    "    \n",
    "    async def a_measure(self, test_case: LLMTestCase):\n",
    "        return self.measure(test_case)\n",
    "    \n",
    "    def is_successful(self):\n",
    "        return self.success\n",
    "    \n",
    "    @property\n",
    "    def __name__(self):\n",
    "        return \"Rouge Metric\"\n",
    "    \n",
    "test_case = LLMTestCase(input=\"Is python better than R\",actual_output=\"Yes it is\" , expected_output=\"yes\")\n",
    "metric = RougeMetric()\n",
    "\n",
    "metric.measure(test_case)\n",
    "print(metric.is_successful())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More than one testcases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using Vertex AI Model, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing Vertex AI Model, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 2 test case(s) in parallel: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|100% (2/2) [Time Taken: 00:04,  2.49s/test case]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.5, strict: False, evaluation model: Vertex AI Model, reason: The score is 1.00 because the output provides a direct and concise answer to the question without any irrelevant statements., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: who won the IPL 2024\n",
      "  - actual output: KKR\n",
      "  - expected output: KKR won it\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.5, strict: False, evaluation model: Vertex AI Model, reason: The score is 1.00 because the output provides a direct and accurate answer to the user's question without any irrelevant information., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: What is Virat's sirname?\n",
      "  - actual output: Kohli\n",
      "  - expected output: Virat Kohli is the sirname\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Tests finished üéâ! View results on \n",
       "<a href=\"https://app.confident-ai.com/project/cm456pth10ome11cml3ab9sf5/evaluation/test-runs/cm4iniavx1164ejfn9s3viltp/test-cases\" target=\"_blank\"><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://app.confident-ai.com/project/cm456pth10ome11cml3ab9sf5/evaluation/test-runs/cm4iniavx1164ejfn9s3viltp/test-</span></a>\n",
       "<a href=\"https://app.confident-ai.com/project/cm456pth10ome11cml3ab9sf5/evaluation/test-runs/cm4iniavx1164ejfn9s3viltp/test-cases\" target=\"_blank\"><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">cases</span></a><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">.</span>\n",
       "‚ÄºÔ∏è  Friendly reminder üòá: You can also run evaluations with ALL of deepeval's metrics directly on Confident AI \n",
       "instead.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Tests finished üéâ! View results on \n",
       "\u001b]8;id=217053;https://app.confident-ai.com/project/cm456pth10ome11cml3ab9sf5/evaluation/test-runs/cm4iniavx1164ejfn9s3viltp/test-cases\u001b\\\u001b[4;94mhttps://app.confident-ai.com/project/cm456pth10ome11cml3ab9sf5/evaluation/test-runs/cm4iniavx1164ejfn9s3viltp/test-\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b]8;id=217053;https://app.confident-ai.com/project/cm456pth10ome11cml3ab9sf5/evaluation/test-runs/cm4iniavx1164ejfn9s3viltp/test-cases\u001b\\\u001b[4;94mcases\u001b[0m\u001b]8;;\u001b\\\u001b[4;94m.\u001b[0m\n",
       "‚ÄºÔ∏è  Friendly reminder üòá: You can also run evaluations with ALL of deepeval's metrics directly on Confident AI \n",
       "instead.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "EvaluationResult(test_results=[TestResult(name='test_case_0', success=True, metrics_data=[MetricData(name='Answer Relevancy', threshold=0.5, success=True, score=1.0, reason='The score is 1.00 because the output provides a direct and concise answer to the question without any irrelevant statements.', strict_mode=False, evaluation_model='Vertex AI Model', error=None, evaluation_cost=None, verbose_logs='Statements:\\n[\\n    \"KKR\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]')], conversational=False, multimodal=False, input='who won the IPL 2024', actual_output='KKR', expected_output='KKR won it', context=None, retrieval_context=None), TestResult(name='test_case_1', success=True, metrics_data=[MetricData(name='Answer Relevancy', threshold=0.5, success=True, score=1.0, reason=\"The score is 1.00 because the output provides a direct and accurate answer to the user's question without any irrelevant information.\", strict_mode=False, evaluation_model='Vertex AI Model', error=None, evaluation_cost=None, verbose_logs='Statements:\\n[\\n    \"Kohli\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]')], conversational=False, multimodal=False, input=\"What is Virat's sirname?\", actual_output='Kohli', expected_output='Virat Kohli is the sirname', context=None, retrieval_context=None)], confident_link='https://app.confident-ai.com/project/cm456pth10ome11cml3ab9sf5/evaluation/test-runs/cm4iniavx1164ejfn9s3viltp/test-cases')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.metrics import HallucinationMetric, AnswerRelevancyMetric\n",
    "from deepeval.dataset import EvaluationDataset\n",
    "from deepeval.test_case import LLMTestCase\n",
    "\n",
    "first_test_case = LLMTestCase(input=\"who won the IPL 2024\",actual_output=\"KKR\" , expected_output=\"KKR won it\")\n",
    "second_test_case = LLMTestCase(input=\"What is Virat's sirname?\",actual_output=\"Kohli\" , expected_output=\"Virat Kohli is the sirname\")\n",
    "\n",
    "test_cases = [first_test_case,second_test_case]\n",
    "\n",
    "dataset = EvaluationDataset(test_cases=test_cases)\n",
    "answer_relevancy_metric = AnswerRelevancyMetric(threshold=0.5,model=vertexai_gemini)\n",
    "\n",
    "#dataset.evaluate([answer_relevancy_metric])\n",
    "\n",
    "# we can also call the evaluate() function directly\n",
    "evaluate(dataset,[answer_relevancy_metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the original text to be summarized\n",
    "input = \"\"\"\n",
    "The 'coverage score' is calculated as the percentage of assessment questions\n",
    "for which both the summary and the original document provide a 'yes' answer. This\n",
    "method ensures that the summary not only includes key information from the original\n",
    "text but also accurately represents it. A higher coverage score indicates a\n",
    "more comprehensive and faithful summary, signifying that the summary effectively\n",
    "encapsulates the crucial points and details from the original content.\n",
    "\"\"\"\n",
    "\n",
    "# This is the summary, replace this with the actual output from your LLM application\n",
    "actual_output=\"\"\"\n",
    "The coverage score quantifies how well a summary captures and\n",
    "accurately represents key information from the original text,\n",
    "with a higher score indicating greater comprehensiveness.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\TEJKIRAN\\anaconda3\\envs\\deepeval\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for\n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\TEJKIRAN\\anaconda3\\envs\\deepeval\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for\n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\TEJKIRAN\\anaconda3\\envs\\deepeval\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for\n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\TEJKIRAN\\anaconda3\\envs\\deepeval\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for\n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\TEJKIRAN\\anaconda3\\envs\\deepeval\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for\n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\TEJKIRAN\\anaconda3\\envs\\deepeval\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for\n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\TEJKIRAN\\anaconda3\\envs\\deepeval\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for\n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\TEJKIRAN\\anaconda3\\envs\\deepeval\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for\n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\TEJKIRAN\\anaconda3\\envs\\deepeval\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for\n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\TEJKIRAN\\anaconda3\\envs\\deepeval\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for\n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\TEJKIRAN\\anaconda3\\envs\\deepeval\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for\n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\TEJKIRAN\\anaconda3\\envs\\deepeval\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for\n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\TEJKIRAN\\anaconda3\\envs\\deepeval\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for\n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\TEJKIRAN\\anaconda3\\envs\\deepeval\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for\n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\TEJKIRAN\\anaconda3\\envs\\deepeval\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for\n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\TEJKIRAN\\anaconda3\\envs\\deepeval\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for\n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\TEJKIRAN\\anaconda3\\envs\\deepeval\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for\n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\TEJKIRAN\\anaconda3\\envs\\deepeval\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for\n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\TEJKIRAN\\anaconda3\\envs\\deepeval\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for\n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\TEJKIRAN\\anaconda3\\envs\\deepeval\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for\n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "The score is 0.67 because while there is no contradicting or extra information present in the summary, it fails to answer a question which the original text could answer.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Summarization Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">4</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mSummarization Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-\u001b[0m\u001b[1;38;2;55;65;81m4\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 1 test case(s) in parallel: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|100% (1/1) [Time Taken: 00:20, 20.18s/test case]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Summarization (score: 0.6666666666666666, threshold: 0.5, strict: False, evaluation model: gpt-4, reason: The score is 0.67 because the summary is mostly accurate without any contradictions or extra information. However, it fails to answer some questions that could be answered by the original text, hence the reduction in the score., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: \n",
      "The 'coverage score' is calculated as the percentage of assessment questions\n",
      "for which both the summary and the original document provide a 'yes' answer. This\n",
      "method ensures that the summary not only includes key information from the original\n",
      "text but also accurately represents it. A higher coverage score indicates a\n",
      "more comprehensive and faithful summary, signifying that the summary effectively\n",
      "encapsulates the crucial points and details from the original content.\n",
      "\n",
      "  - actual output: \n",
      "The coverage score quantifies how well a summary captures and\n",
      "accurately represents key information from the original text,\n",
      "with a higher score indicating greater comprehensiveness.\n",
      "\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Summarization: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Tests finished üéâ! View results on \n",
       "<a href=\"https://app.confident-ai.com/project/cm456pth10ome11cml3ab9sf5/evaluation/test-runs/cm4iotbot139e4u9k2q4luhn1/test-cases\" target=\"_blank\"><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://app.confident-ai.com/project/cm456pth10ome11cml3ab9sf5/evaluation/test-runs/cm4iotbot139e4u9k2q4luhn1/test-</span></a>\n",
       "<a href=\"https://app.confident-ai.com/project/cm456pth10ome11cml3ab9sf5/evaluation/test-runs/cm4iotbot139e4u9k2q4luhn1/test-cases\" target=\"_blank\"><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">cases</span></a><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">.</span>\n",
       "‚ÄºÔ∏è  Friendly reminder üòá: You can also run evaluations with ALL of deepeval's metrics directly on Confident AI \n",
       "instead.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Tests finished üéâ! View results on \n",
       "\u001b]8;id=600536;https://app.confident-ai.com/project/cm456pth10ome11cml3ab9sf5/evaluation/test-runs/cm4iotbot139e4u9k2q4luhn1/test-cases\u001b\\\u001b[4;94mhttps://app.confident-ai.com/project/cm456pth10ome11cml3ab9sf5/evaluation/test-runs/cm4iotbot139e4u9k2q4luhn1/test-\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b]8;id=600536;https://app.confident-ai.com/project/cm456pth10ome11cml3ab9sf5/evaluation/test-runs/cm4iotbot139e4u9k2q4luhn1/test-cases\u001b\\\u001b[4;94mcases\u001b[0m\u001b]8;;\u001b\\\u001b[4;94m.\u001b[0m\n",
       "‚ÄºÔ∏è  Friendly reminder üòá: You can also run evaluations with ALL of deepeval's metrics directly on Confident AI \n",
       "instead.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "EvaluationResult(test_results=[TestResult(name='test_case_0', success=True, metrics_data=[MetricData(name='Summarization', threshold=0.5, success=True, score=0.6666666666666666, reason='The score is 0.67 because the summary is mostly accurate without any contradictions or extra information. However, it fails to answer some questions that could be answered by the original text, hence the reduction in the score.', strict_mode=False, evaluation_model='gpt-4', error=None, evaluation_cost=0.07937999999999999, verbose_logs='Truths (limit=None):\\n[\\n    \"The \\'coverage score\\' is calculated as the percentage of assessment questions for which both the summary and the original document provide a \\'yes\\' answer.\",\\n    \"The method of calculating the \\'coverage score\\' ensures the summary not only includes key information from the original text but also accurately represents it.\",\\n    \"A higher coverage score indicates a more comprehensive and faithful summary.\",\\n    \"The coverage score signifies that the summary effectively encapsulates the crucial points and details from the original content.\"\\n] \\n \\nClaims:\\n[\\n    \"The coverage score quantifies how well a summary captures key information from the original text.\",\\n    \"The coverage score quantifies how well a summary accurately represents key information from the original text.\",\\n    \"A higher score indicates greater comprehensiveness.\"\\n] \\n \\nAssessment Questions:\\n[\\n    \"Is the coverage score based on a percentage of \\'yes\\' answers?\",\\n    \"Does the score ensure the summary\\'s accuracy with the source?\",\\n    \"Does a higher score mean a more comprehensive summary?\"\\n] \\n \\nCoverage Verdicts:\\n[\\n    {\\n        \"summary_verdict\": \"no\",\\n        \"original_verdict\": \"yes\",\\n        \"question\": \"Is the coverage score based on a percentage of \\'yes\\' answers?\"\\n    },\\n    {\\n        \"summary_verdict\": \"yes\",\\n        \"original_verdict\": \"yes\",\\n        \"question\": \"Does the score ensure the summary\\'s accuracy with the source?\"\\n    },\\n    {\\n        \"summary_verdict\": \"yes\",\\n        \"original_verdict\": \"yes\",\\n        \"question\": \"Does a higher score mean a more comprehensive summary?\"\\n    }\\n] \\n \\nAlignment Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]')], conversational=False, multimodal=False, input=\"\\nThe 'coverage score' is calculated as the percentage of assessment questions\\nfor which both the summary and the original document provide a 'yes' answer. This\\nmethod ensures that the summary not only includes key information from the original\\ntext but also accurately represents it. A higher coverage score indicates a\\nmore comprehensive and faithful summary, signifying that the summary effectively\\nencapsulates the crucial points and details from the original content.\\n\", actual_output='\\nThe coverage score quantifies how well a summary captures and\\naccurately represents key information from the original text,\\nwith a higher score indicating greater comprehensiveness.\\n', expected_output=None, context=None, retrieval_context=None)], confident_link='https://app.confident-ai.com/project/cm456pth10ome11cml3ab9sf5/evaluation/test-runs/cm4iotbot139e4u9k2q4luhn1/test-cases')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.metrics import SummarizationMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "\n",
    "test_case = LLMTestCase(input=input, actual_output=actual_output)\n",
    "metric = SummarizationMetric(\n",
    "    threshold=0.5,\n",
    "    model=\"gpt-4\",\n",
    "    assessment_questions=[\n",
    "        \"Is the coverage score based on a percentage of 'yes' answers?\",\n",
    "        \"Does the score ensure the summary's accuracy with the source?\",\n",
    "        \"Does a higher score mean a more comprehensive summary?\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "metric.measure(test_case)\n",
    "print(metric.score)\n",
    "print(metric.reason)\n",
    "\n",
    "# or evaluate test cases in bulk\n",
    "evaluate([test_case], [metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepeval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
